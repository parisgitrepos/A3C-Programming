{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from multiprocessing import Process, Queue\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class RL_Process(Process):\n",
    "    def __init__(self, *args, env: gym.Env = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recv_messages = Queue()\n",
    "        self.running = False\n",
    "        self.message_handlers = {'quit': self.quit}\n",
    "        self.env = env\n",
    "        \n",
    "    def create_networks(self):\n",
    "        import tensorflow as tf\n",
    "        self.tf = tf\n",
    "        self.actor = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Conv2D(filters = 16, kernel_size = 7, strides = 4, input_shape = self.env.observation_space.shape),\n",
    "#             tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(self.env.action_space.n)\n",
    "        ])\n",
    "        self.critic = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Conv2D(filters = 16, kernel_size = 7, strides = 4, input_shape = self.env.observation_space.shape),\n",
    "#             tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "        obs = self.env.reset()\n",
    "        obs = np.expand_dims(obs, 0)\n",
    "        self.actor(obs)\n",
    "        self.critic(obs)\n",
    "        \n",
    "    def quit(self, message):\n",
    "        print(\"Received quit message\")\n",
    "        self.running = False\n",
    "        \n",
    "    def run(self):\n",
    "        self.running = True\n",
    "        self.create_networks()\n",
    "        while self.running:\n",
    "            if not self.recv_messages.empty():\n",
    "                message = self.recv_messages.get()\n",
    "                message_id = message['id']\n",
    "                if message_id in self.message_handlers:\n",
    "                    self.message_handlers[message_id](message)\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid message received: {message}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma, standardized: bool = False):\n",
    "    discounted_rewards = np.zeros_like(rewards)\n",
    "    R = 0\n",
    "    for t in reversed(range(len(rewards))):                   \n",
    "        R = R * gamma + rewards[t]\n",
    "        discounted_rewards[t] = R\n",
    "    if standardized:\n",
    "        mean = np.mean(discounted_rewards)\n",
    "        discounted_rewards -= mean\n",
    "        standard_deviation = np.std(discounted_rewards)\n",
    "        discounted_rewards/=(standard_deviation + np.finfo(np.float32).eps) \n",
    "    return discounted_rewards\n",
    "\n",
    "class Worker_Process(RL_Process):\n",
    "    def __init__(self, *args, batch_size = 30, nn_process_queue = None, worker_id = 0, max_timesteps = 100, gamma = 0.95, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.max_timesteps = max_timesteps\n",
    "        self.nn_process_queue = nn_process_queue\n",
    "        self.worker_id = worker_id\n",
    "        self.message_handlers.update(train = self.train_batch) # same as next line\n",
    "        self.message_handlers['train'] = self.train_batch\n",
    "        self.message_handlers['weights'] = self.set_weights\n",
    "    \n",
    "    def create_networks(self):\n",
    "        super().create_networks()\n",
    "        seed = hash(self.worker_id)\n",
    "        self.env.seed(seed)\n",
    "        self.tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    def send_message(self, message_id, **kwargs):\n",
    "        message = dict(id = message_id, **kwargs)\n",
    "        self.nn_process_queue.put(message)\n",
    "    \n",
    "    def choose_action(self, obs):\n",
    "        obs = np.expand_dims(obs, axis = 0)\n",
    "        logits = self.actor.predict(obs)\n",
    "        probablity_weights = self.tf.nn.softmax(logits = logits).numpy()[0]\n",
    "        action = np.random.choice(env.action_space.n, 1, p = probablity_weights)[0]\n",
    "        return action\n",
    "\n",
    "    def estimate_value(self, obs):\n",
    "        obs = np.expand_dims(obs, axis = 0)\n",
    "        value = self.critic.predict(obs)\n",
    "        return value\n",
    "   \n",
    "    def critic_loss(self, observations, rewards):\n",
    "        huber_loss = self.tf.keras.losses.Huber(reduction=self.tf.keras.losses.Reduction.SUM)\n",
    "        values = self.critic(observations)\n",
    "        loss = huber_loss(values, rewards)\n",
    "        return loss\n",
    "\n",
    "    def actor_loss(self, actions, observations, values, rewards):\n",
    "        advantage = rewards - values\n",
    "        logits = self.actor(observations)\n",
    "        negative_log_prob = self.tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = actions)\n",
    "        loss = self.tf.reduce_mean(negative_log_prob*advantage)\n",
    "        return loss\n",
    "    \n",
    "    def run_episode(self):\n",
    "        obs = self.env.reset()\n",
    "        observations = []\n",
    "        values = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        for t in range(self.max_timesteps):\n",
    "            action = self.choose_action(obs)\n",
    "            value = self.estimate_value(obs)\n",
    "            observations.append(obs)\n",
    "            values.append(value)\n",
    "            actions.append(action)\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "        return observations, actions, values, rewards\n",
    "    \n",
    "    def run_batch(self, episodes, show_progress = False):\n",
    "        batch_observations = []\n",
    "        batch_values = []\n",
    "        batch_rewards = []\n",
    "        batch_actions = []\n",
    "        with tqdm(total = episodes, desc = 'Batch Progress', disable = not show_progress) as progress_bar:\n",
    "            for episode in range(episodes):\n",
    "                observations, actions, values, rewards = self.run_episode()\n",
    "                progress_bar.set_postfix_str(f'Episode Reward: {sum(rewards)}')\n",
    "                progress_bar.update()\n",
    "                batch_observations.extend(observations)\n",
    "                batch_actions.extend(actions)\n",
    "                batch_values.extend(values)\n",
    "                rewards = discount_rewards(rewards, gamma = self.gamma, standardized = False)\n",
    "                batch_rewards.extend(rewards)\n",
    "        return batch_observations, batch_actions, batch_values, batch_rewards\n",
    "    \n",
    "    def train_step(self, observations, actions, values, rewards):\n",
    "        values = np.array(values)\n",
    "        rewards = np.array(rewards)\n",
    "        observations = np.array(observations)\n",
    "        # Step 1. Train actor using critic\n",
    "        with self.tf.GradientTape() as tape:\n",
    "            loss = self.actor_loss(actions, observations, values, rewards)\n",
    "            actor_gradients = tape.gradient(loss, self.actor.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(actor_gradients, self.actor.trainable_variables))\n",
    " \n",
    "        # Step 2. Train critic\n",
    "        with self.tf.GradientTape() as tape:\n",
    "            loss = self.critic_loss(observations, rewards)\n",
    "            critic_gradients = tape.gradient(loss, self.critic.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(critic_gradients, self.critic.trainable_variables))\n",
    "        \n",
    "        return actor_gradients, critic_gradients\n",
    "    \n",
    "    def train_batch(self, message):\n",
    "        episode_assignment = message['episode_assignment']\n",
    "        mean_values = []\n",
    "        mean_rewards = []\n",
    "        episodes = []\n",
    "        for episode in range(episode_assignment):\n",
    "            observations, actions, values, rewards = self.run_batch(1, show_progress = False)\n",
    "            episodes.append(episode)\n",
    "            mean_values.append(np.mean(values))\n",
    "            mean_rewards.append(np.mean(rewards))\n",
    "            self.send_message('reward', reward = mean_rewards[-1], worker_id = self.worker_id, episode = episode)\n",
    "            actor_gradients, critic_gradients = self.train_step(observations, actions, values, rewards)\n",
    "            self.send_message('gradients', actor_gradients = actor_gradients, critic_gradients = critic_gradients)\n",
    "        self.send_message('complete', worker_id = self.worker_id, episodes_complete = episode_assignment)\n",
    "        \n",
    "    def set_weights(self, message):\n",
    "        self.actor.set_weights(message['actor_weights'])\n",
    "        self.critic.set_weights(message['critic_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class NN_Process(RL_Process):\n",
    "    def __init__(self, *args, max_workers = 4, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_workers = max_workers\n",
    "        self.workers = [Worker_Process(nn_process_queue=self.recv_messages, worker_id=i, env = self.env) for i in range(max_workers)]\n",
    "        self.worker_rewards = {\n",
    "            worker.worker_id:dict(episodes = [], rewards = []) for worker in self.workers\n",
    "        }\n",
    "        self.worker_plot_styles = {\n",
    "            worker.worker_id: f\"{'rb'[i%2]}.\" for i, worker in enumerate(self.workers)\n",
    "        }\n",
    "        self.message_handlers['gradients'] = self.apply_gradients\n",
    "        self.message_handlers['complete'] = self.worker_complete\n",
    "        self.message_handlers['start_training'] = self.setup_worker_assignments\n",
    "        self.message_handlers['reward'] = self.reward_update\n",
    "    \n",
    "    def reward_update(self, message):\n",
    "        self.worker_rewards[message['worker_id']]['rewards'].append(message['reward'])\n",
    "        self.worker_rewards[message['worker_id']]['episodes'].append(message['episode'])\n",
    "        clear_output(wait = True)\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for worker_id, worker_metrics in self.worker_rewards.items():\n",
    "            plt.plot(worker_metrics['episodes'], worker_metrics['rewards'], self.worker_plot_styles[worker_id])\n",
    "            xs.extend(worker_metrics['episodes'])\n",
    "            ys.extend(worker_metrics['rewards'])\n",
    "        if len(xs) > len(self.workers):\n",
    "            poly = np.polyfit(xs, ys, 1)\n",
    "            plt.plot((0, max(xs)), (poly[1], poly[1] + max(xs)*poly[0]), 'k-')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Rewards')\n",
    "        plt.show()\n",
    "    \n",
    "    def apply_gradients(self, message):\n",
    "        self.optimizer.apply_gradients(zip(message['actor_gradients'], self.actor.trainable_variables))\n",
    "        self.optimizer.apply_gradients(zip(message['critic_gradients'], self.critic.trainable_variables))\n",
    "        \n",
    "    def send_message(self, worker_id, message_id, **kwargs):\n",
    "        message = dict(id = message_id, **kwargs)\n",
    "        if worker_id < self.max_workers:\n",
    "            self.workers[worker_id].recv_messages.put(message)\n",
    "        else:\n",
    "            raise ValueError(f'Worker ID {worker_id} is invalid')\n",
    "        \n",
    "    def worker_complete(self, message):\n",
    "        worker_id = message['worker_id']\n",
    "        episodes_complete = message['episodes_complete']\n",
    "        self.pending_episodes -= episodes_complete\n",
    "        if self.total_episodes > 0:\n",
    "            self.assign_work(worker_id)\n",
    "        else:\n",
    "            self.send_message(worker_id, 'quit')\n",
    "            if self.pending_episodes <= 0:\n",
    "                self.running = False\n",
    "            \n",
    "    def start_training(self, total_episodes = 100, episodes_per_assignment = 50, max_steps_per_episode = 500):\n",
    "        for worker in self.workers:\n",
    "            if not worker.is_alive():\n",
    "                worker.start()\n",
    "        self.total_episodes = total_episodes\n",
    "        self.episodes_per_assignment = episodes_per_assignment\n",
    "        self.start()\n",
    "        self.recv_messages.put(dict(id = 'start_training', total_episodes = total_episodes, episodes_per_assignment = episodes_per_assignment, \n",
    "                                    max_steps_per_episode = max_steps_per_episode))\n",
    "        \n",
    "    def setup_worker_assignments(self, message):\n",
    "        self.total_episodes = message['total_episodes']\n",
    "        self.pending_episodes = 0\n",
    "        self.episodes_per_assignment = message['episodes_per_assignment']\n",
    "        for worker in self.workers:\n",
    "            self.assign_work(worker.worker_id)\n",
    "            \n",
    "    def assign_work(self, worker_id):\n",
    "        episode_assignment = min(self.episodes_per_assignment, self.total_episodes)\n",
    "        if episode_assignment > 0:\n",
    "            self.total_episodes -= episode_assignment\n",
    "            self.pending_episodes += episode_assignment\n",
    "            self.send_weights(worker_id)\n",
    "            self.send_message(worker_id, 'train', episode_assignment = episode_assignment)\n",
    "        \n",
    "    def send_weights(self, worker_id):\n",
    "        self.send_message(worker_id, 'weights', actor_weights = self.actor.get_weights(), \n",
    "                          critic_weights = self.critic.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received quit message\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "nn_manager = NN_Process(env = env, max_workers = 2)\n",
    "nn_manager.start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
